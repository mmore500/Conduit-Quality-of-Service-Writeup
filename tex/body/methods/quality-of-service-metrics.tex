\subsection{Quality of Service Metrics} \label{sec:quality-of-service-metrics}

\input{fig/quality-of-service-metric-definitions.tex}

The best-effort communication model eschews insulation of computation from  real-time message delivery dynamics.
Because these dynamics are difficult to predict \textit{a priori} and can bias computation and its results, a thorough, empirical account is necessary.
To this end, we introduce a suite of quality of service metrics below.
Figure \ref{fig:quality-of-service-metric-definitions} provides space-time diagrams illustrating the metrics presented in this section.

For the purposes of these metrics, we assume that simulations proceed in an iterative fashion with alternating compute and communication phases.
For short, we refer to a single compute-communication cycle as a ``simstep.''
We derive formulas for metrics in terms of independent observations preceding and succeeding a ``snapshot'' window, during which the simulation and any associated best-effort communication proceeds unimpeded.
The following section, \ref{sec:quality-of-service-experiments}, details the experimental apparatus used to generate quality of service metrics reported in this work.

\subsubsection{Simstep Period} \label{sec:simstep-period-metric}

We calculate the amount of wall-time elapsed per simulation update cycle (``Simstep Period'') during a snapshot window as
\begin{align*}
\frac{
  \mathrm{update\ count\ after} - \mathrm{update\ count\ before}
}{
  \mathrm{wall-time\ after} - \mathrm{wall-time\ before}
}.
\end{align*}
Figure \ref{fig:quality-of-service-metric-definitions-simstep-period} compares a scenario with low simstep period to a scenario with a higher simstep period.

\subsubsection{Simstep Latency} \label{sec:wall-time-latency-metric}

This metric reports the number of simulation iterations that elapse between message dispatch and message delivery.
Figure \ref{fig:quality-of-service-metric-definitions-latency} compares a scenario with low latency to a scenario with a higher latency.

To insulate against imperfect clock synchronization between processes, we estimate one-way wall-time latency from a round-trip measure.
As part of our instrumentation, each simulation element maintains an independent zero-initialized ``touch counter'' associated with every neighbor simulation element it communicates with.
Dispatched messages originating from each simulation element are bundled with the value of the unique touch counter associated with the target element's counter.
When a message is received back to the originating element from the target element, the touch counter is set to $1 + \mathrm{bundled\ touch\ count}$.
In this manner, the touch counter increments by two for each successful round trip completed.
(Because simulation elements are arranged as a toroidal mesh, all interaction between simulation elements is reciprocal.)

We therefore calculate one-way latency during a snapshot window as,
\begin{align*}
  \frac{
    \mathrm{update\ count\ after} - \mathrm{update\ count\ before}
  }{
    \min\Big( \mathrm{ touch\ count\ after } - \mathrm{ touch\ count\ before }, 1 \Big)
  }
\end{align*}
with a best-case assumption for cases where no touches elapsed during the snapshot window.

%TODO reference @rodsan's derivation and proof

\subsubsection{Wall-time Latency} \label{sec:simulation-time-latency-metric}

Wall-time latency is closely related to simstep latency, except that interpret time in terms of elapsed simulation updates instead of wall time.
To calculate wall-time latency we apply a conversion to simstep latency based on simstep period,
\begin{align*}
  \mathrm{simstep\ latency} \times \mathrm{simstep\ period}.
\end{align*}

This metric directly tells the real-time performance of message transmission.
Although it directly follows from the interaction between simstep period and wall-time latency, it complements simstep latency's convenient interpretation in terms of potential simulation mechanics (e.g., simulation elements tending to see data from two updates ago versus from ten).

In addition to simstep latency, Figure \ref{fig:quality-of-service-metric-definitions-latency} is also representative of wall-time latency --- the difference being interpretation of $y$ axis in terms of wall-time instead of elapsed simulation updates.

\subsubsection{Delivery Failure Rate} \label{sec:delivery-failure-rate-metric}

Delivery failure rate measures the fraction of messages sent that are dropped.
The only condition where messages are dropped is when a send buffer fills.
(Under the existing MPI-based implementation, messages that queue on the send buffer are guaranteed for delivery.)
So, we can calculate
\begin{align*}
  \frac{
    \mathrm{successful send odometer after} - \mathrm{successful send odometer before}
  }{
    \mathrm{attempted send odometer after} - \mathrm{attempted send odometer before}
  }.
\end{align*}

\subsubsection{Delivery Clumpiness} \label{sec:delivery-clumpiness-metric}

Delivery clumpiness seeks to quantify the extent to which message arrival is consolidated to a subset of message pull attempts.
We refer to pull attempts that retrieve a message as ``laden.''
That is, the extent to which independently dispatched messages arrive in bundles rather than as an even stream.

If messages all arrive in independent pull attempts, then clumpiness will be zero.
At the point where the pigeonhole principle applies ($\mathrm{num arriving messages} >= \mathrm{num pull attempts}$), clumpiness will also be zero so long as every pull attempt is laden.
If all messages arrive during a single pull attempt, then clumpiness will approach 1.

We formulate clumpiness as the compliment of steadiness.
Steadiness, in turn, stems from three component statistics,
\begin{align*}
\mathrm{num laden pulls elapsed} =& \mathrm{laden pull odometer after} \\
  &- \mathrm{laden pull odometer before} \\
\mathrm{num messages received} =& \mathrm{message odometer after} \\
  &- \mathrm{message odometer before} \\
\mathrm{num pulls attempted} =& \mathrm{pull attempt odometer after} \\
  &- \mathrm{pull attempt odometer before}
.
\end{align*}

We combine $\mathrm{num messages received}$ and $\mathrm{num pulls attempted}$ to derive,
\begin{align*}
  \mathrm{num laden pull opportunities} =& \\
   &\min\Big(\mathrm{num messages received}, \mathrm{num pulls attempted}\Big).
\end{align*}

Then, to calculate steadiness,
\begin{align*}
  \frac{
    \mathrm{num laden pulls elapsed}
  }{
    \mathrm{num laden pull opportunities}
  }.
\end{align*}

Finally, we find delivery clumpiness as $1 - \mathrm{steadiness}$.
Figure \ref{fig:quality-of-service-metric-definitions-clumpiness} compares a scenario with low clumpiness to a scenario with higher clumpiness.
